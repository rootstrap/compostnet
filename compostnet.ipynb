{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/sarahmfrost/compostnet/blob/bryan/compostnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AwsFi6FO7Y20"
   },
   "source": [
    "# Download the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "r-bOtE0qZWR8",
    "outputId": "4c689029-9d21-458c-cec7-0416b57e57c4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import ipdb\n",
    "\n",
    "#BASE_DIR = os.path.join('/content','gdrive','My Drive','dataset-compost-net-resized')\n",
    "#ipdb.set_trace()\n",
    "#!ls gdrive/My\\ Drive/dataset-compost-net-resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "gkbiFoIPZ5Dz",
    "outputId": "0f78a49b-a2c2-4bc2-ac68-5c20c1a4b1b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019_Frost_CompostNet_GHTC.pdf model.h5\r\n",
      "Pipfile                        model.pkl\r\n",
      "Pipfile.lock                   \u001b[1m\u001b[36mmodel_object\u001b[m\u001b[m\r\n",
      "README.md                      model_pickle.obj\r\n",
      "commands.txt                   \u001b[1m\u001b[36mscripts\u001b[m\u001b[m\r\n",
      "\u001b[1m\u001b[36mcompostnet-dataset-resized\u001b[m\u001b[m     splitter.py\r\n",
      "compostnet.ipynb               training_logs.csv\r\n",
      "\u001b[1m\u001b[36mfigures\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "#DATA_DIR = BASE_DIR+\"/image\"\n",
    "\n",
    "#os.chdir(DATA_DIR)\n",
    "!ls\n",
    "\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "#MODEL_SUMMARY_FILE = \"/tmp/model_summary.txt\"\n",
    "#TEST_FILE = \"/tmp/test_file.txt\"\n",
    "\n",
    "training_data_dir  = 'compostnet-dataset-resized/training/'\n",
    "test_data_dir = 'compostnet-dataset-resized/test/'\n",
    "\n",
    "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
    "MODEL_FILE = \"model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IvfJiAF-qU02"
   },
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    " \n",
    "IMAGE_WIDTH, IMAGE_HEIGHT = 400, 300\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSI1SLjH7hql"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AG1z6dR7cnu"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "duq56bJwxqDs"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 844
    },
    "colab_type": "code",
    "id": "b66AZ5N68Hym",
    "outputId": "e0b4482d-2695-428d-83f0-a368f4d474cf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, ZeroPadding2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "#!pip install livelossplot\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVuAVuhy7eKO"
   },
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYbg_pd47fnx"
   },
   "source": [
    "# Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LIbbjkurI38"
   },
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "training_data_generator = ImageDataGenerator(\n",
    "  rescale = 1./255,\n",
    "  validation_split=0.3\n",
    ")\n",
    "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "id": "jeelsCllrdma",
    "outputId": "ea77dd38-b3b2-4f5a-acfb-a821c03aea3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1417 images belonging to 2 classes.\n",
      "Found 606 images belonging to 2 classes.\n",
      "Found 504 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "training_generator = training_data_generator.flow_from_directory(\n",
    "  training_data_dir,\n",
    "  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "  batch_size = BATCH_SIZE,\n",
    "  class_mode='categorical',\n",
    "  subset='training')\n",
    "validation_generator = training_data_generator.flow_from_directory(\n",
    "  training_data_dir,\n",
    "  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "  batch_size = BATCH_SIZE,\n",
    "  class_mode='categorical',\n",
    "  subset='validation')\n",
    "test_generator = test_data_generator.flow_from_directory(\n",
    "  test_data_dir,\n",
    "  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
    "  color_mode=\"rgb\",\n",
    "  batch_size = 1,\n",
    "  class_mode=\"categorical\",\n",
    "  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTximYjN7hBw"
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8S2anwWh7m_J"
   },
   "outputs": [],
   "source": [
    "def build_2convolutional_layer_model(width, height, layers):\n",
    "  \"\"\" Builds a x3 CNN and add details later\n",
    "      https://machinelearningmastery.com/keras-functional-api-deep-learning/\n",
    "  \"\"\"\n",
    "  \n",
    "  input = Input(shape=(width, height, layers))\n",
    "  \n",
    "  # first feature extractor\n",
    "  conv1 = Conv2D(32, kernel_size=3, activation='relu')(input)\n",
    "  conv2 = Conv2D(32, kernel_size=3, activation='relu')(conv1)\n",
    "  pool1 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "  \n",
    "  conv3 = Conv2D(64, 3, 3, activation='relu')(pool1)\n",
    "  conv4 = Conv2D(64, 3, 3, activation='relu')(conv3)\n",
    "  pool2 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "  \n",
    "  conv5 = Conv2D(128, 3, 3, activation='relu')(pool2)\n",
    "  conv6 = Conv2D(128, 3, 3, activation='relu')(conv3)\n",
    "  pool3 = MaxPooling2D(pool_size=(2,2))(conv6)\n",
    "  \n",
    "  conv7 = Conv2D(256, 3, 3, activation='relu')(pool3)\n",
    "  conv8 = Conv2D(256, 3, 3, activation='relu')(conv3)\n",
    "  pool4 = MaxPooling2D(pool_size=(2,2))(conv8)\n",
    "  \n",
    "  flat = Flatten()(pool4)\n",
    "  hidden1 = Dense(256, activation='relu')(flat)\n",
    "  drop1 = Dropout(0.5)(hidden1)\n",
    "  \n",
    "  hidden2= Dense(256, activation='relu')(drop1)\n",
    "  drop2 = Dropout(0.5)(hidden2)\n",
    "  \n",
    "  \n",
    "  # prediction output\n",
    "  output = Dense(1, activation='sigmoid')(drop2)\n",
    "  \n",
    "  model = Model(inputs=input, outputs=output)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "colab_type": "code",
    "id": "OB6c929BAD_E",
    "outputId": "2462558a-5513-4e47-c4f1-48b6a0fa6453"
   },
   "outputs": [],
   "source": [
    "model = build_2convolutional_layer_model(IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1087
    },
    "colab_type": "code",
    "id": "-gnJ0zT8vrjn",
    "outputId": "133f80ad-aa63-4f47-92fe-47c5dd93c77e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 300, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 398, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 396, 296, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 198, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 66, 49, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 22, 16, 256)       147712    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 8, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 22528)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5767424   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 6,009,825\n",
      "Trainable params: 6,009,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJ_jckxj7itm"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WK-DGTPq7I_B"
   },
   "outputs": [],
   "source": [
    "# updatable plot\n",
    "# a minimal example (sort of)\n",
    "\n",
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "3DzAGxHervzi",
    "outputId": "b0f46229-5e1b-43aa-afb7-0279e679c18f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-acfa4136ab0d>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "177/177 [==============================] - 153s 862ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7466 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7483\n",
      "Epoch 2/20\n",
      "177/177 [==============================] - 294s 2s/step - loss: 1.1921e-07 - categorical_accuracy: 0.7480 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 3/20\n",
      "177/177 [==============================] - 165s 929ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7480 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 4/20\n",
      "177/177 [==============================] - 163s 922ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7473 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 5/20\n",
      "177/177 [==============================] - 160s 901ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7473 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7483\n",
      "Epoch 6/20\n",
      "177/177 [==============================] - 160s 903ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7488 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 7/20\n",
      "177/177 [==============================] - 162s 913ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7480 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 8/20\n",
      "177/177 [==============================] - 159s 897ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7466 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7467\n",
      "Epoch 9/20\n",
      "177/177 [==============================] - 160s 906ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7459 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7450\n",
      "Epoch 10/20\n",
      "177/177 [==============================] - 154s 871ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7466 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7483\n",
      "Epoch 11/20\n",
      "177/177 [==============================] - 230s 1s/step - loss: 1.1921e-07 - categorical_accuracy: 0.7488 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7483\n",
      "Epoch 12/20\n",
      "177/177 [==============================] - 172s 970ms/step - loss: 1.1921e-07 - categorical_accuracy: 0.7466 - val_loss: 1.1921e-07 - val_categorical_accuracy: 0.7467\n",
      "Epoch 13/20\n",
      "140/177 [======================>.......] - ETA: 32s - loss: 1.1921e-07 - categorical_accuracy: 0.7547"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      training_generator,\n",
    "      steps_per_epoch=len(training_generator.filenames) // BATCH_SIZE,\n",
    "      epochs=EPOCHS,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=len(validation_generator.filenames) // BATCH_SIZE,\n",
    "      #callbacks=[\n",
    "      #    plot_losses, keras.callbacks.CSVLogger(\n",
    "      #        TRAINING_LOGS_FILE,\n",
    "      #        append=False,\n",
    "      #        separator=\";\"\n",
    "      #    )\n",
    "      #],\n",
    "  verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save history object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "file_pi = open('history.obj', 'w')\n",
    "\n",
    "pickle.dump(model, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save wights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle \n",
    "\n",
    "#file_pi = open('model_pickle.obj', 'w')\n",
    "\n",
    "#pickle.dump(model, file_pi)\n",
    "\n",
    "from keras.models import load_model\n",
    "model.load_weights(MODEL_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i30eoFrp7j4E"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "6Avfm1RyFcUy",
    "outputId": "888cd6f4-0a1e-46b3-ff0d-9328a7b3c42d"
   },
   "outputs": [],
   "source": [
    "label_map = (test_generator.class_indices)\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ng3Eg414sPMT"
   },
   "outputs": [],
   "source": [
    "#open(TEST_FILE,\"w\")\n",
    "STEP_SIZE_TEST=test_generator.n\n",
    "probabilities = model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "\n",
    "print(probabilities[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gitxb6LuHIvE"
   },
   "outputs": [],
   "source": [
    "filenames = test_generator.filenames\n",
    "nb_samples = len(filenames)\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhexZh74E7MQ"
   },
   "outputs": [],
   "source": [
    "metrics = model.evaluate_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "print(model.metrics_names)\n",
    "print(metrics)\n",
    "\n",
    "#8571428656578064"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate(test_generator, steps=STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "def plot_results(history):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNZ11qcAFeGb"
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict_generator(test_generator, steps=STEP_SIZE_TEST)\n",
    "print(probabilities)\n",
    "print(len(probabilities))\n",
    "import numpy as np\n",
    "np.unique(probabilities, axis=0)\n",
    "test_generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD-qzzR9LkBi"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "labels = ['class_recyclable', 'class_trash']\n",
    "\n",
    "trash_total = 0\n",
    "\n",
    "for i in range(0,504):\n",
    "  x,y = test_generator.next()\n",
    "  if y.argmax(axis=-1)[0] == 1:\n",
    "    trash_total += 1\n",
    "trash_total/504\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcIcMkBKB1CV"
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "labels = ['class_recyclable', 'class_trash']\n",
    "\n",
    "for i in range(0,20):\n",
    "  x,y = test_generator.next()\n",
    "  image = x[0]\n",
    "  plt.imshow(image)\n",
    "  y_prob = model.predict(x)\n",
    "  print(y_prob)\n",
    "  y_classes = y_prob.argmax(axis=-1)\n",
    "  plt.xlabel(\"Prediction: \" + labels[y_classes[0]] + \" Actual: \" + labels[y.argmax(axis=-1)[0]])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdFalOyADV3S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "compostnet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
